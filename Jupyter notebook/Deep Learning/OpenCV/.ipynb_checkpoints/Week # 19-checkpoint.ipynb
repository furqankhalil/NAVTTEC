{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('E:\\Speech to Text\\Hasan-Ali.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the individual color levels for the first pixel (0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 15 29\n",
      "(234, 351, 3)\n"
     ]
    }
   ],
   "source": [
    "# BGR Values for the first 0,0 pixel\n",
    "B, G, R = image[0, 0] \n",
    "print(B, G, R)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens when we convert it to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234, 351)\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "print(gray_img.shape)\n",
    "print(gray_img[0, 0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now only 2 dimensions. Each pixel coordinate has only one value (previously 3) with a range of 0 to 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_img[0, 0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another useful color space is HSV \n",
    "Infact HSV is very useful in color filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#H: 0 - 180, S: 0 - 255, V: 0 - 255\n",
    "\n",
    "image = cv2.imread('E:\\Speech to Text\\Hasan-Ali.jpg')\n",
    "\n",
    "hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "cv2.imshow('Orignl', image)\n",
    "cv2.imshow('HSV image', hsv_image)\n",
    "cv2.imshow('Hue channel', hsv_image[:, :, 0])\n",
    "cv2.imshow('Saturation channel', hsv_image[:, :, 1])\n",
    "cv2.imshow('Value channel', hsv_image[:, :, 2])\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now explore lookng at individual channels in an RGB image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 1200)\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('E:\\Speech to Text\\Hasan-Ali.jpg')\n",
    "\n",
    "# OpenCV's 'split' function splites the image into each color index\n",
    "B, G, R = cv2.split(image)\n",
    "\n",
    "print(B.shape)\n",
    "cv2.imshow(\"Red\", R)\n",
    "cv2.imshow(\"Green\", G)\n",
    "cv2.imshow(\"Blue\", B)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Let's re-make the original image, \n",
    "merged = cv2.merge([B, G, R]) \n",
    "cv2.imshow(\"Merged\", merged) \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's amplify the blue color\n",
    "merged = cv2.merge([B, G, R+70])\n",
    "cv2.imshow(\"Merged with Blue Amplified\", merged) \n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "B, G, R = cv2.split(image)\n",
    "\n",
    "# Let's create a matrix of zeros \n",
    "# with dimensions of the image h x w  \n",
    "zeros = np.zeros(image.shape[:2], dtype = \"uint8\")\n",
    "\n",
    "cv2.imshow(\"Red\", cv2.merge([zeros, zeros, R]))\n",
    "cv2.imshow(\"Green\", cv2.merge([zeros, G, zeros]))\n",
    "cv2.imshow(\"Blue\", cv2.merge([B, zeros, zeros]))\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load a simple image with 3 black squares\n",
    "image = cv2.imread('E:\\Speech to Text\\Blac.jpg') #shapes_donut\n",
    "cv2.imshow('Input Image', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Grayscale\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find Canny edges\n",
    "edged = cv2.Canny(gray, 30, 200)\n",
    "cv2.imshow('Canny Edges', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Finding Contours\n",
    "# Use a copy of your image e.g. edged.copy(), since findContours alters the image\n",
    "contours, hierarchy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) #retr_list\n",
    "cv2.imshow('Canny Edges After Contouring', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "print(\"Number of Contours found = \" + str(len(contours)))\n",
    "\n",
    "# Draw all contours\n",
    "# Use '-1' as the 3rd parameter to draw all\n",
    "cv2.drawContours(image, contours,-1, (0,0,100), 1) # second BGR and third for thickness\n",
    "\n",
    "cv2.imshow('Contours', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our image\n",
    "image = cv2.imread('E:\\Speech to Text\\Blac.jpg')\n",
    "cv2.imshow('Original image' , image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Create a black image with same dimensions as our loaded image\n",
    "blank_image = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "cv2.imshow('blank_imagee', blank_image)\n",
    "cv2.waitKey(0)\n",
    "# Create a copy of our original image\n",
    "orginal_image = image\n",
    "\n",
    "# Grayscale our image\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find Canny edges\n",
    "edged = cv2.Canny(gray, 50, 200)\n",
    "cv2.imshow('1 - Canny Edges', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Find contours and print how many were found\n",
    "contours, hierarchy = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "print (\"Number of contours found = \", len(contours))\n",
    "\n",
    "#Draw all contours\n",
    "cv2.drawContours(blank_image, contours, -1, (0,255,0), 3)\n",
    "cv2.imshow('2 - All Contours over blank image', blank_image)\n",
    "cv2.waitKey(0)q\n",
    "\n",
    "# Draw all contours over blank image\n",
    "cv2.drawContours(image, contours, -1, (0,255,0), 3)\n",
    "cv2.imshow('3 - All Contours', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
